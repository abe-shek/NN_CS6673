{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, n0, n1, n2):\n",
    "        self.n_0 = n0\n",
    "        self.n_1 = n1\n",
    "        self.n_2 = n2\n",
    "\n",
    "        self.reinitialize_weights = True\n",
    "        \n",
    "        # weights and biases initialized as placeholders.\n",
    "        # reinitialized later\n",
    "        self.weights_1 = np.zeros((self.n_0, self.n_1), dtype=int)\n",
    "        self.weights_2 = np.zeros((self.n_1, self.n_2), dtype=int)\n",
    "        self.biases_1 = np.zeros((1, self.n_1), dtype=int)\n",
    "        self.biases_2 = np.zeros((1, self.n_2), dtype=int)\n",
    "\n",
    "        self.activations_1 = np.zeros((1, self.n_1), dtype=int)\n",
    "        self.activations_2 = np.zeros((1, self.n_2), dtype=int)\n",
    "        self.sensitivities_1 = np.zeros((1, self.n_1), dtype=int)\n",
    "        self.sensitivities_2 = np.zeros((1, self.n_2), dtype=int)\n",
    "\n",
    "        self.hyper_params = HyperParams()\n",
    "\n",
    "        self.model_info = Info()\n",
    "\n",
    "\n",
    "class HyperParams:\n",
    "    def __init__(self):\n",
    "        self.alpha_list = [0.1, 0.2, 0.3]\n",
    "        self.zeta_list = [0.5, 1, 1.5]\n",
    "        self.x0_list = [0.5, 1, 1.5]\n",
    "        self.max_epochs = 700  # empirically chosen\n",
    "        self.tolerance = 0.05\n",
    "        self.learning_rate = self.alpha_list[1]\n",
    "        self.zeta = self.zeta_list[1]\n",
    "        self.x0 = self.x0_list[1]\n",
    "        self.cost_fn = 0  # {0: quadratic, 1: cross-entropy}\n",
    "\n",
    "\n",
    "class Info:\n",
    "    def __init__(self, total_epochs=0, last_epoch_error=0.0, convergence=False):\n",
    "        self.total_epochs_req = total_epochs\n",
    "        self.last_epoch_error = last_epoch_error\n",
    "        self.converged = convergence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sheets = {}\n",
    "\n",
    "\n",
    "def update_sheet(writer, sheet_name, sheet_obj):\n",
    "    df_obj = {\n",
    "        'Model architecture': sheet_obj['model_arch_list'],\n",
    "        'Model weights': sheet_obj['model_weight_list'],\n",
    "        'Model biases': sheet_obj['model_bias_list'],\n",
    "        '# Training epochs': sheet_obj['total_epochs_req_list'],\n",
    "        'Learning Rate': sheet_obj['learning_rate_list'],\n",
    "        'Zeta': sheet_obj['zeta_list'],\n",
    "        'X0': sheet_obj['x0_list'],\n",
    "        'Cost Function': sheet_obj['cost_fn_list'],\n",
    "        'Last epoch error': sheet_obj['last_epoch_error_list'],\n",
    "        'Did converge?': sheet_obj['converged_list'],\n",
    "    }\n",
    "    df = pd.DataFrame(df_obj)\n",
    "    df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "\n",
    "def save_data(sheet_name, model):\n",
    "    try:\n",
    "        sheet_obj = sheets[sheet_name]\n",
    "    except KeyError:\n",
    "        sheet_obj = {}\n",
    "    if not sheet_obj:\n",
    "        sheet_obj = {'model_arch_list': [], 'model_weight_list': [], 'model_bias_list': [],\n",
    "                     'total_epochs_req_list': [], 'learning_rate_list': [], 'zeta_list': [],\n",
    "                     'x0_list': [], 'cost_fn_list': [], 'last_epoch_error_list': [],\n",
    "                     'converged_list': []}\n",
    "    sheet_obj['model_arch_list'].append(\"[ \" + str(model.n_0) + \", \" + str(model.n_1) +\n",
    "                                        \", \" + str(model.n_2) + \"]\")\n",
    "    sheet_obj['model_weight_list'].append(\"Weights1 = \" + str(model.weights_1) +\n",
    "                                          \"\\nWeights2 = \" + str(model.weights_2))\n",
    "    sheet_obj['model_bias_list'].append(\"Biases1 = \" + str(model.biases_1) +\n",
    "                                        \"\\nBiases2 = \" + str(model.biases_2))\n",
    "    sheet_obj['total_epochs_req_list'].append(model.model_info.total_epochs_req)\n",
    "    sheet_obj['learning_rate_list'].append(model.hyper_params.learning_rate)\n",
    "    sheet_obj['zeta_list'].append(model.hyper_params.zeta)\n",
    "    sheet_obj['x0_list'].append(model.hyper_params.x0)\n",
    "    sheet_obj['cost_fn_list'].append(\"Quadratic\" if model.hyper_params.cost_fn == 0\n",
    "                                     else \"Cross-Entropy\")\n",
    "    sheet_obj['last_epoch_error_list'].append(model.model_info.last_epoch_error)\n",
    "    sheet_obj['converged_list'].append(\"Yes\" if model.model_info.converged else \"No\")\n",
    "    sheets[sheet_name] = sheet_obj\n",
    "\n",
    "\n",
    "def export_data():\n",
    "    print(\"Starting export\")\n",
    "    writer = pd.ExcelWriter('Results.xlsx', engine='xlsxwriter')\n",
    "    if not writer:\n",
    "        print(\"Error while opening writer. Exiting.\")\n",
    "        return\n",
    "    for sheet_name in sheets:\n",
    "        sheet_obj = sheets[sheet_name]\n",
    "        if not sheet_obj:\n",
    "            print(\"Skipping sheet - %s \" % sheet_name)\n",
    "            continue\n",
    "        print(\"Updating sheet - %s \" % sheet_name)\n",
    "        update_sheet(writer, sheet_name, sheet_obj)\n",
    "    writer.save()\n",
    "    print(\"Data exported\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:62: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1=\n",
      "[[ 0.19347555  0.31675476 -0.144748    0.36374521]\n",
      " [ 0.30686735  0.18845288 -0.03301594 -0.48859019]]\n",
      "b1=\n",
      "[[-0.32243413  0.26504268  0.27330512 -0.32503622]]\n",
      "W2=\n",
      "[[ 0.47534885]\n",
      " [-0.27642811]\n",
      " [-0.38395025]\n",
      " [ 0.34801327]]\n",
      "b2=\n",
      "[[-0.08027444]]\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate = 0.1 | Zeta = 0.5 | x0 = 0.5\n",
      "Convergence = True | Training Epochs = 144 | Squared Error = 0.049873341492876956\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate = 0.1 | Zeta = 0.5 | x0 = 1\n",
      "Convergence = False | Training Epochs = 700 | Squared Error = 0.055927975170455696\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate = 0.1 | Zeta = 0.5 | x0 = 1.5\n",
      "Convergence = False | Training Epochs = 700 | Squared Error = 4.0477393613429244\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate = 0.1 | Zeta = 1 | x0 = 0.5\n",
      "Convergence = True | Training Epochs = 97 | Squared Error = 0.049637115432790604\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate = 0.1 | Zeta = 1 | x0 = 1\n",
      "Convergence = True | Training Epochs = 640 | Squared Error = 0.04986490264371217\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate = 0.1 | Zeta = 1 | x0 = 1.5\n",
      "Convergence = False | Training Epochs = 700 | Squared Error = 0.3720739550348952\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate = 0.1 | Zeta = 1.5 | x0 = 0.5\n",
      "Convergence = False | Training Epochs = 700 | Squared Error = 4.000705200611622\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate = 0.1 | Zeta = 1.5 | x0 = 1\n",
      "Convergence = True | Training Epochs = 458 | Squared Error = 0.049987887286957175\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate = 0.1 | Zeta = 1.5 | x0 = 1.5\n",
      "Convergence = False | Training Epochs = 700 | Squared Error = 0.14315651838094595\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate = 0.2 | Zeta = 0.5 | x0 = 0.5\n",
      "Convergence = False | Training Epochs = 700 | Squared Error = 4.862384115264075\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate = 0.2 | Zeta = 0.5 | x0 = 1\n",
      "Convergence = False | Training Epochs = 700 | Squared Error = 4.204958347834154\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate = 0.2 | Zeta = 0.5 | x0 = 1.5\n",
      "Convergence = False | Training Epochs = 700 | Squared Error = 4.094065865517321\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate = 0.2 | Zeta = 1 | x0 = 0.5\n",
      "Convergence = True | Training Epochs = 52 | Squared Error = 0.048779595735270326\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate = 0.2 | Zeta = 1 | x0 = 1\n",
      "Convergence = True | Training Epochs = 408 | Squared Error = 0.04991055755562201\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate = 0.2 | Zeta = 1 | x0 = 1.5\n",
      "Convergence = True | Training Epochs = 631 | Squared Error = 0.04988909483521971\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate = 0.2 | Zeta = 1.5 | x0 = 0.5\n",
      "Convergence = True | Training Epochs = 69 | Squared Error = 0.04907998529277527\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate = 0.2 | Zeta = 1.5 | x0 = 1\n",
      "Convergence = True | Training Epochs = 224 | Squared Error = 0.04987026445288031\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate = 0.2 | Zeta = 1.5 | x0 = 1.5\n",
      "Convergence = True | Training Epochs = 553 | Squared Error = 0.04999293222262656\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate = 0.3 | Zeta = 0.5 | x0 = 0.5\n",
      "Convergence = True | Training Epochs = 54 | Squared Error = 0.049039109630381855\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate = 0.3 | Zeta = 0.5 | x0 = 1\n",
      "Convergence = False | Training Epochs = 700 | Squared Error = 4.310545405999978\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate = 0.3 | Zeta = 0.5 | x0 = 1.5\n",
      "Convergence = False | Training Epochs = 700 | Squared Error = 4.138021047560265\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate = 0.3 | Zeta = 1 | x0 = 0.5\n",
      "Convergence = True | Training Epochs = 31 | Squared Error = 0.04995314267186744\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate = 0.3 | Zeta = 1 | x0 = 1\n",
      "Convergence = True | Training Epochs = 185 | Squared Error = 0.049735165791450764\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate = 0.3 | Zeta = 1 | x0 = 1.5\n",
      "Convergence = True | Training Epochs = 605 | Squared Error = 0.04984200046100855\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate = 0.3 | Zeta = 1.5 | x0 = 0.5\n",
      "Convergence = True | Training Epochs = 27 | Squared Error = 0.04787247678823797\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate = 0.3 | Zeta = 1.5 | x0 = 1\n",
      "Convergence = True | Training Epochs = 137 | Squared Error = 0.049822583171420486\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate = 0.3 | Zeta = 1.5 | x0 = 1.5\n",
      "Convergence = True | Training Epochs = 391 | Squared Error = 0.04992550078242809\n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      "Number of convergent hyper parameter combinations = 17 (out of 27)\n",
      "Convergence for N1 = 1 -> 0\n",
      "Convergence for N1 = 2 -> 82\n",
      "Convergence for N1 = 4 -> 100\n",
      "Convergence for N1 = 6 -> 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convergence for N1 = 8 -> 100\n",
      "Convergence for N1 = 10 -> 98\n",
      "Convergence results for N1 = [1,2,4,6,8,10] (out of 100): [0, 82, 100, 100, 100, 98]\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate = 0.1 | Zeta = 0.5 | x0 = 0.5\n",
      "Convergence = True | Training Epochs = 130 | Squared Error = 0.04818403472549024\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate = 0.1 | Zeta = 0.5 | x0 = 1\n",
      "Convergence = True | Training Epochs = 273 | Squared Error = 0.04920549727660134\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate = 0.1 | Zeta = 0.5 | x0 = 1.5\n",
      "Convergence = True | Training Epochs = 537 | Squared Error = 0.049217856264777524\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate = 0.1 | Zeta = 1 | x0 = 0.5\n",
      "Convergence = True | Training Epochs = 59 | Squared Error = 0.04812216331925205\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate = 0.1 | Zeta = 1 | x0 = 1\n",
      "Convergence = True | Training Epochs = 189 | Squared Error = 0.048827557727704765\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate = 0.1 | Zeta = 1 | x0 = 1.5\n",
      "Convergence = True | Training Epochs = 481 | Squared Error = 0.04918584143788117\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate = 0.1 | Zeta = 1.5 | x0 = 0.5\n",
      "Convergence = True | Training Epochs = 32 | Squared Error = 0.04730144103192096\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate = 0.1 | Zeta = 1.5 | x0 = 1\n",
      "Convergence = True | Training Epochs = 93 | Squared Error = 0.04935925793673039\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate = 0.1 | Zeta = 1.5 | x0 = 1.5\n",
      "Convergence = True | Training Epochs = 169 | Squared Error = 0.04935280121677305\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate = 0.2 | Zeta = 0.5 | x0 = 0.5\n",
      "Convergence = True | Training Epochs = 48 | Squared Error = 0.04729646661090205\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate = 0.2 | Zeta = 0.5 | x0 = 1\n",
      "Convergence = False | Training Epochs = 700 | Squared Error = 4.4181942951797675\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate = 0.2 | Zeta = 0.5 | x0 = 1.5\n",
      "Convergence = False | Training Epochs = 700 | Squared Error = 4.275074610028772\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate = 0.2 | Zeta = 1 | x0 = 0.5\n",
      "Convergence = True | Training Epochs = 30 | Squared Error = 0.04450862905880065\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate = 0.2 | Zeta = 1 | x0 = 1\n",
      "Convergence = True | Training Epochs = 61 | Squared Error = 0.04999468286965289\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate = 0.2 | Zeta = 1 | x0 = 1.5\n",
      "Convergence = True | Training Epochs = 143 | Squared Error = 0.049281296908125924\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate = 0.2 | Zeta = 1.5 | x0 = 0.5\n",
      "Convergence = True | Training Epochs = 15 | Squared Error = 0.04682004586369068\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate = 0.2 | Zeta = 1.5 | x0 = 1\n",
      "Convergence = True | Training Epochs = 56 | Squared Error = 0.04877838809480512\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate = 0.2 | Zeta = 1.5 | x0 = 1.5\n",
      "Convergence = True | Training Epochs = 174 | Squared Error = 0.048719322156361364\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate = 0.3 | Zeta = 0.5 | x0 = 0.5\n",
      "Convergence = False | Training Epochs = 700 | Squared Error = 5.302362039146319\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate = 0.3 | Zeta = 0.5 | x0 = 1\n",
      "Convergence = False | Training Epochs = 700 | Squared Error = 4.638025288751011\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate = 0.3 | Zeta = 0.5 | x0 = 1.5\n",
      "Convergence = False | Training Epochs = 700 | Squared Error = 4.41819429503458\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate = 0.3 | Zeta = 1 | x0 = 0.5\n",
      "Convergence = True | Training Epochs = 15 | Squared Error = 0.04426839330093334\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate = 0.3 | Zeta = 1 | x0 = 1\n",
      "Convergence = True | Training Epochs = 26 | Squared Error = 0.043646433081242504\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate = 0.3 | Zeta = 1 | x0 = 1.5\n",
      "Convergence = True | Training Epochs = 118 | Squared Error = 0.04929856228031971\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate = 0.3 | Zeta = 1.5 | x0 = 0.5\n",
      "Convergence = True | Training Epochs = 11 | Squared Error = 0.049505345251627336\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate = 0.3 | Zeta = 1.5 | x0 = 1\n",
      "Convergence = True | Training Epochs = 31 | Squared Error = 0.049029234653004204\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate = 0.3 | Zeta = 1.5 | x0 = 1.5\n",
      "Convergence = True | Training Epochs = 82 | Squared Error = 0.04785224419009246\n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      "Number of convergent hyper parameter combinations = 22 (out of 27)\n",
      "Convergence for N1 = 1 -> 0\n",
      "Convergence for N1 = 2 -> 59\n",
      "Convergence for N1 = 4 -> 90\n",
      "Convergence for N1 = 6 -> 96\n",
      "Convergence for N1 = 8 -> 97\n",
      "Convergence for N1 = 10 -> 100\n",
      "Convergence results for N1 = [1,2,4,6,8,10] (out of 100): [0, 59, 90, 96, 97, 100]\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate = 0.2 | Zeta = 1.0 | x0 = 1.0\n",
      "Convergence = False | Training Epochs = 1 | Squared Error = 5.3801314005663095\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import getopt\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "from model import Model, HyperParams\n",
    "from save import save_data, export_data\n",
    "\n",
    "export_to_excel = False\n",
    "\n",
    "\n",
    "def transfer_ftn(n_l, x0):\n",
    "    a_l = np.tanh(n_l / (2 * x0))\n",
    "    return a_l\n",
    "\n",
    "\n",
    "# we only save a_l NOT n_l if using bipolar sigmoid transfer function\n",
    "def derivative_transfer_ftn(a_l, x0):\n",
    "    derivative = ((1 + a_l) * (1 - a_l)) / (2 * x0)\n",
    "    return derivative\n",
    "\n",
    "\n",
    "def init_weights_biases(model):\n",
    "    if model.reinitialize_weights:\n",
    "        model.weights_1 = np.random.uniform(-1 * model.hyper_params.zeta,\n",
    "                                            model.hyper_params.zeta, model.weights_1.shape)\n",
    "\n",
    "        model.weights_2 = np.random.uniform(-1 * model.hyper_params.zeta,\n",
    "                                            model.hyper_params.zeta, model.weights_2.shape)\n",
    "\n",
    "        model.biases_1 = np.random.uniform(-1 * model.hyper_params.zeta,\n",
    "                                           model.hyper_params.zeta, model.biases_1.shape)\n",
    "\n",
    "        model.biases_2 = np.random.uniform(-1 * model.hyper_params.zeta,\n",
    "                                           model.hyper_params.zeta, model.biases_2.shape)\n",
    "\n",
    "    return [model.weights_1, model.weights_2], [model.biases_1, model.biases_2]\n",
    "\n",
    "\n",
    "def train_nn(x_train, y_train, model):\n",
    "    Q = len(x_train)\n",
    "    weight_list, bias_list = init_weights_biases(model)\n",
    "    weight_list_len = len(weight_list)\n",
    "    for epoch in range(model.hyper_params.max_epochs):\n",
    "        epoch_error = 0\n",
    "        for iteration in range(Q):\n",
    "            x = x_train[iteration]\n",
    "            y = y_train[iteration]\n",
    "            x = np.array(x).reshape((1, len(x)))\n",
    "            y = np.array(y).reshape((1, len(y)))\n",
    "\n",
    "            # Calculate activations for all layers\n",
    "            # don't need to save n_l if we are using bipolar sigmoid transfer function\n",
    "            a_l_list = [x]\n",
    "            for i in range(len(weight_list)):\n",
    "                n_l = np.matmul(a_l_list[-1], weight_list[i]) + bias_list[i]\n",
    "                a_l = transfer_ftn(n_l, model.hyper_params.x0)\n",
    "                a_l_list.append(a_l)\n",
    "\n",
    "            # calculating the error for this example\n",
    "            y_hat = a_l_list[-1]  # activation of the last layer\n",
    "            example_error = np.matmul(y_hat - y, (y_hat - y).T)\n",
    "            example_error = np.asscalar(example_error)\n",
    "            epoch_error = epoch_error + example_error\n",
    "\n",
    "            # Calculate sensitivities for last layer. Performs element-wise multiplication.\n",
    "            # quadratic cost function\n",
    "            if model.hyper_params.cost_fn == 0:\n",
    "                s_L = np.multiply((y_hat - y), derivative_transfer_ftn(y_hat, model.hyper_params.x0))\n",
    "            # cross entropy cost function\n",
    "            elif model.hyper_params.cost_fn == 1:\n",
    "                s_L = y_hat - y\n",
    "\n",
    "            # Calculate sensitivites for other layers\n",
    "            sensitivities_list = [s_L]\n",
    "\n",
    "            for l in range(weight_list_len - 1, 0, -1):\n",
    "                s_l = np.multiply(np.matmul(sensitivities_list[0], weight_list[l].T), \\\n",
    "                                  derivative_transfer_ftn(a_l_list[l], model.hyper_params.x0))\n",
    "                sensitivities_list.insert(0, s_l)\n",
    "\n",
    "            # Update weights and biases\n",
    "            for l in range(weight_list_len):\n",
    "                weight_list[l] = weight_list[l] - \\\n",
    "                                 (model.hyper_params.learning_rate *\n",
    "                                  np.matmul(a_l_list[l].T, sensitivities_list[l]))\n",
    "\n",
    "                bias_list[l] = bias_list[l] - \\\n",
    "                               (model.hyper_params.learning_rate * sensitivities_list[l])\n",
    "\n",
    "        # epoch error is not normalized (not divided by number of examples)\n",
    "        if epoch_error < model.hyper_params.tolerance:\n",
    "            break\n",
    "\n",
    "    num_training_epochs = epoch + 1\n",
    "    if num_training_epochs < model.hyper_params.max_epochs:\n",
    "        convergence = True\n",
    "    else:\n",
    "        convergence = False\n",
    "\n",
    "    update_model_info(model, weight_list, bias_list, num_training_epochs, epoch_error, convergence)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def update_model_info(model, weight_list, bias_list, num_training_epochs, epoch_error, convergence):\n",
    "    model.weights_1 = weight_list[0]\n",
    "    model.weights_2 = weight_list[1]\n",
    "    model.biases_1 = bias_list[0]\n",
    "    model.biases_2 = bias_list[1]\n",
    "    model.model_info.total_epochs_req = num_training_epochs\n",
    "    model.model_info.last_epoch_error = epoch_error\n",
    "    model.model_info.converged = convergence\n",
    "\n",
    "\n",
    "def extract_model_info(model, sheet_name, verbose=True):\n",
    "    if verbose:\n",
    "        print(\"--------------------------------------------------------------------------------\")\n",
    "        print(f\"Learning rate = {model.hyper_params.learning_rate} | \"\n",
    "              f\"Zeta = {model.hyper_params.zeta} | \"\n",
    "              f\"x0 = {model.hyper_params.x0}\")\n",
    "        print(f\"Convergence = {model.model_info.converged} | \"\n",
    "              f\"Training Epochs = {model.model_info.total_epochs_req} | \"\n",
    "              f\"Squared Error = {model.model_info.last_epoch_error}\")\n",
    "        print(\"--------------------------------------------------------------------------------\")\n",
    "\n",
    "    if export_to_excel:\n",
    "        save_data(sheet_name, model)\n",
    "\n",
    "\n",
    "def part_2a(x_train, y_train, model, sheet_name):\n",
    "    # TODO\n",
    "    # Look for patterns when do we get non-convergent results\n",
    "    # Try all 3X3X3=27 hyper parameter combinations of alpha, zeta and x0\n",
    "    num_convergence = 0\n",
    "    for alpha in model.hyper_params.alpha_list:\n",
    "        for zeta in model.hyper_params.zeta_list:\n",
    "            for x0 in model.hyper_params.x0_list:\n",
    "                model.hyper_params.learning_rate = alpha\n",
    "                model.hyper_params.zeta = zeta\n",
    "                model.hyper_params.x0 = x0\n",
    "                model = train_nn(x_train, y_train, model)\n",
    "                if model.model_info.converged:\n",
    "                    num_convergence += 1\n",
    "                extract_model_info(model, sheet_name, verbose=True)\n",
    "    print(\"-----------------------------------------------------------------------\")\n",
    "    print(f\"Number of convergent hyper parameter combinations = {num_convergence} (out of 27)\")\n",
    "\n",
    "\n",
    "def part_2b(x_train, y_train, cost_fn, sheet_name):\n",
    "    N1_list = [1, 2, 4, 6, 8, 10]\n",
    "    convergence_list = []\n",
    "    for i in range(len(N1_list)):\n",
    "        model = Model(2, N1_list[i], 1)\n",
    "        model.hyper_params.cost_fn = cost_fn\n",
    "        num_convergence = 0\n",
    "        for iters in range(100):\n",
    "            model = train_nn(x_train, y_train, model)\n",
    "            if model.model_info.converged:\n",
    "                num_convergence += 1\n",
    "            extract_model_info(model, sheet_name, verbose=False)\n",
    "        convergence_list.append(num_convergence)\n",
    "        print(f\"Convergence for N1 = %d -> %d\" % (N1_list[i], num_convergence))\n",
    "\n",
    "    print(f\"Convergence results for N1 = [1,2,4,6,8,10] (out of 100): {convergence_list}\")\n",
    "\n",
    "    # Results mostly converge for N1=4 and above. For N1=2, almost 70% of the times,\n",
    "    # it converges. For N1=1, it doesn't converge at all.\n",
    "    # This is probably because the XOR problem is not linearly separable and we need a higher\n",
    "    # number of neurons in the hidden layer to approximate the function (see universality theorem).\n",
    "\n",
    "\n",
    "def xor_weight_validation(x_train, y_train, model, sheet_name):\n",
    "    model.hyper_params.max_epochs = 1\n",
    "\n",
    "    # Setting initial weights and biases for xor weight validation\n",
    "    model.weights_1 = np.array([[0.197, 0.3191, -0.1448, 0.3594],\n",
    "                                [0.3099, 0.1904, -0.0347, -0.4861]]).reshape(model.weights_1.shape)\n",
    "    model.weights_2 = np.array([0.4919, -0.2913, -0.3979, 0.3581]).reshape(model.weights_2.shape)\n",
    "    model.biases_1 = np.array([-0.3378, 0.2771, 0.2859, -0.3329]).reshape(model.biases_1.shape)\n",
    "    model.biases_2 = np.array([-0.1401]).reshape(model.biases_2.shape)\n",
    "    model.reinitialize_weights = False\n",
    "\n",
    "    model = train_nn(x_train, y_train, model)\n",
    "\n",
    "    print(\"W1=\", model.weights_1, sep=\"\\n\")\n",
    "    print(\"b1=\", model.biases_1, sep=\"\\n\")\n",
    "    print(\"W2=\", model.weights_2, sep=\"\\n\")\n",
    "    print(\"b2=\", model.biases_2, sep=\"\\n\")\n",
    "\n",
    "    extract_model_info(model, sheet_name, verbose=False)\n",
    "\n",
    "    # np.savez('xor_weight_validation.npz', model=model)\n",
    "    # results can be loaded from the xor_weight_validation.npz file by uncommenting the following\n",
    "    # data = np.load('Part1_results.npz')\n",
    "    # model = data['model']\n",
    "\n",
    "\n",
    "def main():\n",
    "    # # uncomment this if data needs to be stored in excel\n",
    "    # global export_to_excel\n",
    "    # export_to_excel = True\n",
    "\n",
    "    x_train = [[1, 1], [1, -1], [-1, 1], [-1, -1]]\n",
    "    y_train = [[-1], [1], [1], [-1]]\n",
    "\n",
    "    model = Model(2, 4, 1)\n",
    "    xor_weight_validation(x_train, y_train, model, sheet_name=\"XOR weights validation\")\n",
    "\n",
    "    # using quadratic cost ftn\n",
    "    model = Model(2, 4, 1)\n",
    "    model.hyper_params.cost_fn = 0\n",
    "    part_2a(x_train, y_train, model, sheet_name=\"A-Z-X0 variations (Quad)\")\n",
    "    part_2b(x_train, y_train, cost_fn=0, sheet_name=\"N1 variations (Quad)\")\n",
    "\n",
    "    # using cross entropy cost ftn\n",
    "    model = Model(2, 4, 1)\n",
    "    model.hyper_params.cost_fn = 1\n",
    "    part_2a(x_train, y_train, model, sheet_name=\"A-Z-X0 variations (CrsEnt)\")\n",
    "    part_2b(x_train, y_train, cost_fn=1, sheet_name=\"N1 variations (CrsEnt)\")\n",
    "\n",
    "    model = Model(2, 4, 1)\n",
    "    model.hyper_params.learning_rate = 0.2\n",
    "    model.hyper_params.zeta = 1.0\n",
    "    model.hyper_params.x0 = 1.0\n",
    "    model.hyper_params.cost_fn = 1\n",
    "    model.hyper_params.max_epochs = 1\n",
    "    model = train_nn(x_train, y_train, model)\n",
    "    extract_model_info(model, sheet_name=\"Final verification\")\n",
    "\n",
    "    # should be set to true above\n",
    "    if export_to_excel:\n",
    "        export_data()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
